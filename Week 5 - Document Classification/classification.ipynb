{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Assignment\n",
    "\n",
    "In this assignment you're going to use scikit-learn and optionally any other modules we have used until now for document classification. The data that we're going to work on is Yelp restaurant reviews (more info [here](https://www.yelp.com/dataset_challenge). There are many more dimensions to this set (user info, bussiness info, etc.) but we're only going to focus on the review part. It's structured like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    'type': 'review',\n",
    "    'business_id': (encrypted business id),\n",
    "    'user_id': (encrypted user id),\n",
    "    'stars': (star rating, rounded to half-stars),\n",
    "    'text': (review text),\n",
    "    'date': (date, formatted like '2012-03-14'),\n",
    "    'votes': {(vote type): (count)},\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very big (2.3 GB), so make sure that you select only as much as your computer can process. You can do this by changing the `max_reviews` variable below. However, do take care that the fewer reviews you are using, the less well you're going to perform on training data, and generalize to new data.\n",
    "\n",
    "## The Assignment\n",
    "\n",
    "Using a Jupyter Notebook to document classification processes is becoming popular in research. Not only does it contain a more verbose explanation of your thinking process than a paper, it also shows the code you're using and allows for direct reproduction. You're going to walk through all steps below, change the code to make a working classification document, and improve performance on this task. While doing so, you can use the *report here* boxes to describe your process and the **motivation** for your choices.\n",
    "\n",
    "## What to Submit\n",
    "\n",
    "You save your version of the .ipynb and submit it on blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the correct field from the JSON file you are provided to load the text (our data) and stars (our labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "max_reviews = 10000\n",
    "X, y = [], []\n",
    "\n",
    "with open('./data/yelp_academic_dataset_review.json') as f:\n",
    "    for i, jsf in enumerate(f):\n",
    "        review = json.loads(jsf)  # this is the JSON file\n",
    "        \n",
    "        text = ''  # your answer here\n",
    "        stars = '' # your answer here\n",
    "        \n",
    "        X.append(text)\n",
    "        y.append(stars)\n",
    "        \n",
    "        if i == max_reviews:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Preprocessing\n",
    "\n",
    "This is the part where we do manual cleaning, or other preprocessing steps, add to the preprocessing function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, x in enumerate(X):\n",
    "    X[i] = x.lower()\n",
    "    # do some other things to document x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Interpretation\n",
    "\n",
    "Finding out things about your data helps you understand performance of your classifier. You would want to do that here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1263, 2: 1030, 3: 1525, 4: 2687, 5: 3496})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Train & Test\n",
    "\n",
    "We make sure we properly evaluate by splitting our data. You can change the parameter of `train_size` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 1000\n",
      "Test instances: 9001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.10, random_state=42)\n",
    "print(\"Training instances:\", len(X_train))\n",
    "print(\"Test instances:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Features & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, we are ready for classification. You are provided with a standard pipeline. Expand on its functionality; try changing the vectorizer and / or its parameters. Add classifiers and change their parameters. Make sure you document ALL things you tried and how they increased cross-validation performance. You're also allowed to change the number of folds (`cv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Cross-Validation: 0.31 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=5, n_jobs=-1)\n",
    "print(\"Accuracy on Cross-Validation: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you're done with a certain set-up above, you are allowed to test on your test set. Do that here. Report the performances and if you went back to another classifier to increase its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test: 0.35 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)  # fitting = training\n",
    "scores = pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy on Test: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Extra\n",
    "\n",
    "Use LIME or graphs to reflect on the performance of your classifier. You need to figure the code out yourself (from the slide examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Report here.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
