{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Excersises\n",
    "\n",
    "**Note**: this week there are no tasks, nothing will be graded. You are free to ask questions regarding these excersises though! What we will do is try to apply some of the code shown in the lectures to kind of get things rolling. As I probably mention in the lecture, it's not important for you to understand all the code shown in detail. This will probably make more sense at the end of your Data Processing lectures. For the time being, try to kind of understand what each function is doing, and more importantly, make sure you understand what each component in the pre-processing pipeline does on a higher level. **Knowing what you are looking at is more important than understanding the code.**\n",
    "\n",
    "## Retrieving HTML\n",
    "\n",
    "We will be using [this](http://www.imdb.com/title/tt0088763/synopsis?ref_=tt_ql_stry_3) page. In the sheet examples, I could conveniently extract all text because they were neatly put around `<p>...</p>` tags. Sadly, this is not the case for the page we are looking at today. Beautifulsoup (the library that makes HTML searchable), can search for more complex patterns though. What you will see a lot is for example `<div class=\"something\">...</div>`. If you want all `div`s, that as class have `something`, the syntax for that is as follows: `soup.find_all('div', {'class': 'something'})`. \n",
    "\n",
    "> Q: How do I get Beautifulsoup?\n",
    "\n",
    "> A: If you're using your own Anaconda install, it should already be in there. On JupyterHub it is NOT installed. Please check with someone who has the library installed if you still want to make this excersise and don't want to install Anaconda.\n",
    "\n",
    "\n",
    "Now try to get the synopsis text for the page using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def url_to_data(url):\n",
    "    \"\"\"Extracts html for a given url.\"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    html = http.request('GET', url).data.decode('utf-8')\n",
    "    return html\n",
    "\n",
    "url = '...'  # add\n",
    "soup = bs(url_to_data(url), \"lxml\")\n",
    "results = soup.find_all('div', {})  # add\n",
    "text = [x.text for x in results][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can mess with `text` here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to apply any of the things we are discussing below to this `text` variable. For now however, we are going to work with another data format, namely JSON. \n",
    "\n",
    "## Working with JSON\n",
    "\n",
    "The Twitter API allows you to search for keywords, or just monitor a live stream of incoming tweets (optionally filtered by some keyword or geolocation constraints). Using this API is out of scope for this class, so I stored the JSON results it gives in a `pickle` file (storage format for Python objects). If you are still interested in reading how to register for the API and some of its functionality, I wrote a [blog post](http://cmry.github.io/notes/twitter-python) on it. The syntax is pretty easy; it boils down to:\n",
    "\n",
    "``` python\n",
    "import tweepy\n",
    "\n",
    "consumer_key = 'XXXXXXXXXXXXXXXXX' # own key you get after registering\n",
    "consumer_secret = 'XXXXXXXXXXXXXXXXX' # own key\n",
    "\n",
    "authentication_token = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(authentication_token)\n",
    "\n",
    "api.find('some_keyword')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q: What is an API?\n",
    "\n",
    "> A: Some websites provide access to their data in some simple format. This usually implies that you send out a simple query to them, and they respond with a standard format that contains the results for your query. In Twitter's example, this is a JSON with the tweet, and meta-data.\n",
    "\n",
    "Twitter wants you to validate your identity and limit your personal use of their service, which is why they require you to provide these two codes (`consumer_key` and `consumer_secret`). The `AppAuthHandler` knocks on Twitter's door, gives them these two keys and, if they are valid, they give you back a certificate (token) you can use to connect to the API. After this, you can use the `api` object to carry out certain operations (`find`, `friends`, `user_timeline` are some examples.\n",
    "\n",
    "\n",
    "Because of privacy reasons, I will not print the actual tweet here. You are welcome to expect the format for yourself though. Just uncomment `tweets[2]` and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tweets = pickle.load(open('data/tweets.pickle', 'rb'))\n",
    "\n",
    "# tweets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a lot of information you can recover from the JSON file of a single tweet. Besides geo information, isolated hashtags, text, retweets etc., the API also provides you with user information per tweet. This includes their name, profile description, profile colours, and activity (favourites, statuses). We can select them by simply nesting calls to the object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n",
      "tell me why McDonald's gave me a sweet tea w no ice?Â¿ #wtffffðŸ™„\n"
     ]
    }
   ],
   "source": [
    "print(tweets[2]['user']['statuses_count'])\n",
    "print(tweets[2]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Tweets\n",
    "\n",
    "We will focus on the text only for this part; which I will store in a simple list. Try to fill in this regex that will tokenize the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r ', 'a ', 'g ', 'd ', 't ', 'g ', 's ', 'f ', 'g ', 't ', 'n '],\n",
       " ['t ', 'u ', 'n ', 'm ', 'n ', 'n ', 'm ', 's '],\n",
       " ['l ', 'e ', 'y ', 's ', 'e ', 'e ', 'a ', 't ', 'a ', 'w ', 'o '],\n",
       " ['s ', 'a ', 'g ', 'h ', 'd ', 'o ', 's ', 'o ', 'y ', 'l '],\n",
       " ['y '],\n",
       " ['t ',\n",
       "  'e ',\n",
       "  'y ',\n",
       "  'e ',\n",
       "  'k ',\n",
       "  'f ',\n",
       "  'y ',\n",
       "  's ',\n",
       "  'e ',\n",
       "  'r ',\n",
       "  's ',\n",
       "  'f ',\n",
       "  'r '],\n",
       " ['s ', 'l ', 'u ', 'n ', 'y ', 'o ', 't ', 't ', 'f ']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tokenized_tweets = []\n",
    "for tweet in tweets:\n",
    "                                        # only edit this part <--------\n",
    "    tokenized_tweets.append([x for x in re.findall('[a-z] ', tweet['text']) if x and x != ' '])\n",
    "    \n",
    "tokenized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you want to try, you can compare your own regex tokenizer to that of SpaCy. I will already fill out the results for those who don't manage to get SpaCy working.\n",
    "\n",
    "> Q: How do I install SpaCy?\n",
    "\n",
    "> A: Again, our JupyterHub doesn't have this available yet. Installation instructions for SpaCy in anaconda are [here](https://spacy.io/docs/#getting-started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['After',\n",
       "  'a',\n",
       "  'long',\n",
       "  'weekend',\n",
       "  'RD',\n",
       "  ',',\n",
       "  '11',\n",
       "  'straight',\n",
       "  'working',\n",
       "  'days',\n",
       "  'awaits',\n",
       "  '!',\n",
       "  '#',\n",
       "  'wtffff',\n",
       "  'bring',\n",
       "  'it',\n",
       "  'on',\n",
       "  'ðŸ‘¯'],\n",
       " ['Waitttt',\n",
       "  'u',\n",
       "  'can',\n",
       "  'zoom',\n",
       "  'in',\n",
       "  'on',\n",
       "  'instagram',\n",
       "  'pics',\n",
       "  'now',\n",
       "  '?',\n",
       "  '!',\n",
       "  '?',\n",
       "  '!',\n",
       "  '#',\n",
       "  'wtffff'],\n",
       " ['tell',\n",
       "  'me',\n",
       "  'why',\n",
       "  'McDonald',\n",
       "  \"'s\",\n",
       "  'gave',\n",
       "  'me',\n",
       "  'a',\n",
       "  'sweet',\n",
       "  'tea',\n",
       "  'w',\n",
       "  'no',\n",
       "  'ice?Â¿',\n",
       "  '#',\n",
       "  'wtffffðŸ™„'],\n",
       " ['there',\n",
       "  \"'s\",\n",
       "  'a',\n",
       "  'breaking',\n",
       "  'Amish',\n",
       "  'kid',\n",
       "  'who',\n",
       "  'goes',\n",
       "  'to',\n",
       "  'my',\n",
       "  'school',\n",
       "  '#',\n",
       "  'wtffff'],\n",
       " ['Candy', 'perrreooooo', '?', '?', '#', 'WTFFFF'],\n",
       " ['I',\n",
       "  'got',\n",
       "  'one',\n",
       "  'question',\n",
       "  '...',\n",
       "  'Why',\n",
       "  'the',\n",
       "  'fu@k',\n",
       "  '30',\n",
       "  '%',\n",
       "  'of',\n",
       "  'my',\n",
       "  'followers',\n",
       "  'are',\n",
       "  'either',\n",
       "  'scammers',\n",
       "  'of',\n",
       "  'pornstars',\n",
       "  '?',\n",
       "  '?',\n",
       "  'ðŸ¤”ðŸ˜‚',\n",
       "  '@twitter',\n",
       "  '#',\n",
       "  'wtffff'],\n",
       " ['WOW',\n",
       "  'is',\n",
       "  'all',\n",
       "  'you',\n",
       "  'can',\n",
       "  'say',\n",
       "  'to',\n",
       "  'that',\n",
       "  'hit',\n",
       "  '#',\n",
       "  'wtffff',\n",
       "  '#',\n",
       "  'LSUvsWISC']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "    \n",
    "spacy_tokens = [[token.text for token in nlp(tweet['text'])] for tweet in tweets]\n",
    "spacy_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think about your regex, does it cover many edge cases that you might consider are seperate tokens? How does SpaCy do? Do you think it is suitable for twitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Examples\n",
    "\n",
    "## Language Identification\n",
    "\n",
    "One of the things we can now do with these tokens is a task called language identification. Basically, you want to know what language a certain tweet was written in (handy if you are working on a specific language, and in general to filter languages). For this example, we will use dictionaries from English and German, and simply count how many words are in each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length English dict 25323\n",
      "Length German dict 1022\n",
      "\n",
      "Tokens in English dict 45\n",
      "Tokens in German dict 1\n",
      "\n",
      "Out of Vocabulary words: {\"'s\", '...', 'ðŸ‘¯', 'amish', 'w', 'rd', 'fu@k', 'waitttt', '#', '!', '11', 'wtffffðŸ™„', 'a', 'ice?Â¿', '30', '%', 'scammers', 'wtffff', 'ðŸ¤”ðŸ˜‚', 'mcdonald', '@twitter', 'perrreooooo', 'pics', 'i', ',', 'lsuvswisc', '?', 'pornstars', 'instagram', 'u'}\n"
     ]
    }
   ],
   "source": [
    "# read the wordlists, make them into a set (list with unique words)\n",
    "english = set(open('data/english-dict.txt').read().split('\\n'))\n",
    "german = set(open('data/german-dict.txt').read().split('\\n'))\n",
    "\n",
    "# flatten the lists in list for the spacy_tokens\n",
    "token_list = [token.lower() for tweet in spacy_tokens for token in tweet]\n",
    "tokens = set(token_list)\n",
    "\n",
    "# task: try to print different variables to see what they contain\n",
    "\n",
    "print(\"Length English dict\", len(english))\n",
    "print(\"Length German dict\", len(german))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Tokens in English dict\", len(tokens & english))\n",
    "print(\"Tokens in German dict\", len(tokens & german))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Out of Vocabulary words:\", tokens - english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sets that we are using (rather than lists) allow for special comparions. You can for example say: give me the words that occur in `tokens` as well as in `english` (`tokens & english`), or give me the words that occur in `tokens` but do NOT occur in `english` (`tokens - english`). The latter would be considered as Out Of Vocabulary (OOV) words. More info [here](https://docs.python.org/2/library/sets.html#set-objects).\n",
    "\n",
    "## Frequencies and Plotting\n",
    "\n",
    "As we saw in the lecutre, once you have your tokens prepared, Python has an easy way of converting these into a list of word frequencies, namely the Counter class. To easily select the most popular words, you can append `most_common(somenumber)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 8),\n",
       " ('wtffff', 6),\n",
       " ('?', 6),\n",
       " ('!', 3),\n",
       " ('a', 3),\n",
       " ('my', 2),\n",
       " ('me', 2),\n",
       " (\"'s\", 2),\n",
       " ('on', 2),\n",
       " ('can', 2)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_frequencies = Counter(token_list)\n",
    "word_frequencies.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python allows for splitting these into for example `word` and `frequency`, by using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words, frequencies = zip(*word_frequencies.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip ties together two variables, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = list(zip(\"a\", \"b\"))\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `zip(*...)` sytnax (using the `*` after `(`) unties them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a',)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b  = zip(*example)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these using `matplotlib`. We can go several ways, first let's try to see how many words have a certain frequency (frequency on x, word frequency on y, i.e. over 60 words have frequency 1). What it shows here is us plotting a list of frequencies as a histogram (`plt.hist`).\n",
    "\n",
    "> Q: How do I install matplotlib?\n",
    "\n",
    "> A: Again, not on JupyterHub (*sigh*), but should be included in Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEACAYAAACqOy3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBS5JjbLAJalRFrgkNer/AFEF792OsJiqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc1f1cf550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "# above shows the plots in jupyter (fancy)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(frequencies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, `matplotlib` cannot handle actual string words in a basic example, so we need to use the Counter class to sort them for us so we can enumerate the frequencies (i.e. the word with rank 1 (most common) has frequency x, etc). This we do by just passing a large number to most_common, or by using the length (bit neater):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ranked = word_frequencies.most_common(len(word_frequencies))\n",
    "ranks, frequencies = zip(*[(rank, pairs[1]) for rank, pairs in enumerate(ranked)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we can use a line chart `plt.plot` and insert the `x` and `y` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbc1f1916d8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEACAYAAACqOy3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJalR/wgPbMVpYxmvXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc1dcbcdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(frequencies, ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
